<!doctype html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <title>Data analysis and interpretation for clinical genomics</title>
        
        <link rel="stylesheet" href="/clinical_genomics/assets/css/bootstrap.min.css?v=3">
        <link rel="stylesheet" href="/clinical_genomics/assets/css/bootstrap-toc.min.css">
        <link rel="stylesheet" href="/clinical_genomics/assets/css/main.css?v=2">
        <link rel="stylesheet" href="/clinical_genomics/assets/css/font-awesome.css">
        <link rel="stylesheet" href="/clinical_genomics/assets/css/academicons.css">
        <link rel="stylesheet" href="/clinical_genomics/assets/css/syntax_highlighting.css">
        <link rel="shortcut icon" href="/clinical_genomics/favicon.ico" type="image/x-icon" />

        
        
        
        
        
        <meta name="description" content="Collection of tutorials developed and maintained by the w..." />
        <meta property="og:title" content="Galaxy Training: Data analysis and interpretation for clinical genomics" />
        <meta property="og:description" content="Collection of tutorials developed and maintained by the w..." />
        <meta property="og:image" content="/clinical_genomics/assets/images/GTNLogo1000.png" />
    </head>
    <body data-spy="scroll" data-target="#toc">
        















<div class="container main-content">
    <script type="application/ld+json">
        


{}
    </script>

    <section class="tutorial">
        <h1 data-toc-skip>Data analysis and interpretation for clinical genomics</h1>
        

        <div class="contributors-line">By: 

<a href="/clinical_genomics/hall-of-fame#abrusell" class="contributor-badge"><img src="https://avatars.githubusercontent.com/abrusell" alt="Alessandro Bruselles">Alessandro Bruselles</a>, <a href="/clinical_genomics/hall-of-fame#aciolfi" class="contributor-badge"><img src="https://avatars.githubusercontent.com/aciolfi" alt="Andrea Ciolfi">Andrea Ciolfi</a>, <a href="/clinical_genomics/hall-of-fame#gmauro" class="contributor-badge"><img src="https://avatars.githubusercontent.com/gmauro" alt="Gianmauro Cuccuru">Gianmauro Cuccuru</a>, <a href="/clinical_genomics/hall-of-fame#m-giuseppe" class="contributor-badge"><img src="https://avatars.githubusercontent.com/m-giuseppe" alt="Giuseppe Marangi">Giuseppe Marangi</a>, <a href="/clinical_genomics/hall-of-fame#puva" class="contributor-badge"><img src="https://avatars.githubusercontent.com/puva" alt="Paolo Uva">Paolo Uva</a>, <a href="/clinical_genomics/hall-of-fame#tommasopippucci" class="contributor-badge"><img src="https://avatars.githubusercontent.com/tommasopippucci" alt="Tommaso Pippucci">Tommaso Pippucci</a>

</div>

        <blockquote class="overview">
            <h3>Overview</h3>
            <strong><i class="fa fa-question-circle" aria-hidden="true"></i><span class="visually-hidden">question</span> Questions</strong>
            <ul>
            
            <li><p>What are the specific challenges for the interpretation of sequencing data in the clinical setting?</p>
</li>
            
            <li><p>How can you annotate variants in a clinically-oriented perspective?</p>
</li>
            
            </ul>

            <strong><i class="fa fa-bullseye" aria-hidden="true"></i><span class="visually-hidden">objectives</span> Objectives</strong>
            <ul>
            
            <li><p>Perform in-depth quality control of sequencing data at multiple levels (fastq, bam, vcf)</p>
</li>
            
            <li><p>Call, classify and annotate variants with information extracted from public databases for clinical interpretation</p>
</li>
            
            <li><p>Analyze CNV and Regions of Homozygosity (ROH)</p>
</li>
            
            </ul>

            

            
            <p><strong><i class="fa fa-hourglass-end" aria-hidden="true"></i><span class="visually-hidden">time</span> Time estimation:</strong> 6 hours</p>
            

            

            
            

            

            <p><strong> <i class="fa fa-calendar" aria-hidden="true"></i><span class="visually-hidden">last_modification</span> Last modification:</strong> Jan 24, 2020 </p>
        </blockquote>

        <div class="container">
            <div class="row">
                <!-- sidebar, which will move to the top on a small screen -->
                <div class="col-sm-2">
                    <nav id="toc" data-toggle="toc" class="sticky-top"></nav>
                </div>
                <div class="col-sm-10">
                    <h1 class="no_toc" id="introduction">Introduction</h1>

<p>In years 2018-2019, on behalf of the Italian Society of Human Genetics (<a href="https://www.sigu.net/">SIGU</a>) an itinerant <a href="https://usegalaxy.eu/"><span class="notranslate">Galaxy</span></a>-based “hands-on-computer” training activity entitled “Data analysis and interpretation for clinical genomics” was held four times on invitation from different Italian institutions (Università Cattolica del Sacro Cuore in Rome, University of Genova, SIGU 2018 annual scientific meeting in Catania, University of Bari) and was offered to about 30 participants each time among clinical doctors, biologists, laboratory technicians and bioinformaticians. Topics covered by the course were NGS data quality check, detection of variants, copy number alterations and runs of homozygosity, annotation and filtering and clinical interpretation of sequencing results.</p>

<p>Realizing the constant need for training on NGS analysis and interpretation of sequencing data in the clinical setting, we designed an on-line <a href="https://usegalaxy.eu/"><span class="notranslate">Galaxy</span></a>-based training resource articulated in presentations and practical assignments by which students will learn how to approach NGS data quality at the level of fastq, bam and VCF files and clinically-oriented examination of variants emerging from sequencing experiments.</p>

<p>This training course is not to be intended as a tutorial on NGS pipelines and variant calling. This on-line training activity is indeed focused on data analysis for clinical interpretation. If you are looking for training on variant calling, visit this <strong><span class="notranslate">Galaxy</span></strong> tutorial on <a href="https://galaxyproject.github.io/training-material/topics/variant-analysis/tutorials/exome-seq/tutorial.html">Exome sequencing data analysis for diagnosing a genetic disease</a>.</p>

<blockquote>
  <blockquote class="comment">
    <h3 id="comment-sigu"><i class="fa fa-commenting-o" aria-hidden="true"></i><span class="visually-hidden">comment</span> SIGU</h3>
    <p>The <em>Italian Society of Human Genetics</em> (<strong>SIGU</strong>) was established on November 14,
1997, when the pre-existing Italian Association of Medical Genetics and the Italian
Association of Medical Cytogenetics joined.
SIGU is one of the 27 member societies of FEGS (Federation of European Genetic
Societies).
Animated by a predominant scientific spirit, SIGU wants to be reference for
all health-care issues involving human genetics in all its applications.
Its specific missions are to develop quality criteria for medical genetic
laboratories, to promote writing of guidelines in the field of human genetics
and public awareness of the role and limitations of genetic diagnostic techniques. 
SIGU coordinates activities of several working groups: Clinical Genetics,
Cytogenetics, Prenatal Diagnosis, Neurogenetics, Fingerprinting, Oncological 
Genetics, Immunogenetics, Genetic Counseling, Quality Control, Medical Genetics 
Services, Bioethics. More than 1000 medical geneticists and biologists are active
members of the society.</p>
  </blockquote>
</blockquote>

<blockquote class="agenda">
  <h3 id="agenda">Agenda</h3>

  <p>In this tutorial, we will cover:</p>

<ol id="markdown-toc">
  <li><a href="#requirements" id="markdown-toc-requirements">Requirements</a></li>
  <li><a href="#datasets" id="markdown-toc-datasets">Datasets</a>    <ol>
      <li><a href="#get-data" id="markdown-toc-get-data">Get data</a></li>
    </ol>
  </li>
  <li><a href="#next-generation-sequencing" id="markdown-toc-next-generation-sequencing">Next Generation Sequencing</a>    <ol>
      <li><a href="#ngs-in-the-clinic" id="markdown-toc-ngs-in-the-clinic">NGS in the clinic</a></li>
      <li><a href="#basics-of-ngs-bioinformatic-analysis" id="markdown-toc-basics-of-ngs-bioinformatic-analysis">Basics of NGS bioinformatic analysis</a></li>
      <li><a href="#alignment" id="markdown-toc-alignment">Alignment</a></li>
      <li><a href="#post-alignment-bam-processing" id="markdown-toc-post-alignment-bam-processing">Post-alignment BAM processing</a></li>
      <li><a href="#variant-calling" id="markdown-toc-variant-calling">Variant calling</a></li>
    </ol>
  </li>
  <li><a href="#quality-control" id="markdown-toc-quality-control">Quality control</a>    <ol>
      <li><a href="#quality-control-of-fastq-files" id="markdown-toc-quality-control-of-fastq-files">Quality control of FASTQ files</a></li>
      <li><a href="#computation-of-per-base-coverage-depth-at-specific-genomic-intervals" id="markdown-toc-computation-of-per-base-coverage-depth-at-specific-genomic-intervals">Computation of per-base coverage depth at specific genomic intervals</a></li>
    </ol>
  </li>
  <li><a href="#variant-calling-and-classification" id="markdown-toc-variant-calling-and-classification">Variant calling and classification</a></li>
  <li><a href="#variant-annotation" id="markdown-toc-variant-annotation">Variant annotation</a>    <ol>
      <li><a href="#gene-model" id="markdown-toc-gene-model">Gene model</a></li>
      <li><a href="#sequence-variant-nomenclature" id="markdown-toc-sequence-variant-nomenclature">Sequence variant nomenclature</a></li>
      <li><a href="#variant-class" id="markdown-toc-variant-class">Variant class</a></li>
      <li><a href="#population-sequencing-db" id="markdown-toc-population-sequencing-db">Population sequencing db</a></li>
      <li><a href="#variant-diseasegene-disease-db" id="markdown-toc-variant-diseasegene-disease-db">Variant-disease/gene-disease db</a></li>
      <li><a href="#annotation-software-and-tools" id="markdown-toc-annotation-software-and-tools">Annotation Software and tools</a></li>
      <li><a href="#annotation-and-filtering-with-wannovar" id="markdown-toc-annotation-and-filtering-with-wannovar">Annotation and filtering with wANNOVAR</a></li>
      <li><a href="#clinical-databases-for-further-manual-variant-annotation" id="markdown-toc-clinical-databases-for-further-manual-variant-annotation">Clinical databases for further manual variant annotation</a></li>
    </ol>
  </li>
  <li><a href="#variant-prioritization" id="markdown-toc-variant-prioritization">Variant prioritization</a>    <ol>
      <li><a href="#variant-impact" id="markdown-toc-variant-impact">Variant impact</a></li>
      <li><a href="#variant-frequency" id="markdown-toc-variant-frequency">Variant frequency</a></li>
      <li><a href="#variant-effect-prediction-tools" id="markdown-toc-variant-effect-prediction-tools">Variant effect prediction Tools</a></li>
      <li><a href="#acmgamp-2015-guidelines" id="markdown-toc-acmgamp-2015-guidelines">ACMG/AMP 2015 guidelines</a></li>
      <li><a href="#prioritization" id="markdown-toc-prioritization">Prioritization</a></li>
    </ol>
  </li>
  <li><a href="#cnv-detection-from-targeted-sequencing-data" id="markdown-toc-cnv-detection-from-targeted-sequencing-data">CNV detection from targeted sequencing data</a>    <ol>
      <li><a href="#computational-approaches" id="markdown-toc-computational-approaches">Computational approaches</a></li>
      <li><a href="#rc-method-and-data-normalization" id="markdown-toc-rc-method-and-data-normalization">RC method and data normalization</a></li>
      <li><a href="#cnv-detection-accuracy" id="markdown-toc-cnv-detection-accuracy"><em>CNV</em> detection accuracy</a></li>
      <li><a href="#tools-for-cnv-detection-from-gene-panels-or-exome-data" id="markdown-toc-tools-for-cnv-detection-from-gene-panels-or-exome-data">Tools for <em>CNV</em> detection from gene panels or exome data</a></li>
    </ol>
  </li>
  <li><a href="#regions-of-homozygosity" id="markdown-toc-regions-of-homozygosity">Regions of Homozygosity</a>    <ol>
      <li><a href="#homozygosity-mapping" id="markdown-toc-homozygosity-mapping">Homozygosity <span class="notranslate">mapping</span></a></li>
      <li><a href="#computational-approaches-1" id="markdown-toc-computational-approaches-1">Computational approaches</a></li>
    </ol>
  </li>
</ol>

</blockquote>

<h1 id="requirements">Requirements</h1>

<p>This tutorial is based on the <a href="https://galaxyproject.org/"><span class="notranslate">Galaxy</span></a> platform,
therefore a basic knowledge of <span class="notranslate">Galaxy</span> is required to get most out of the course.
In particular, we’ll use European <span class="notranslate">Galaxy</span> server running at <a href="https://usegalaxy.eu">https://use<span class="notranslate">galaxy</span>.eu</a>.</p>

<p>Registration is <strong>free</strong>, and you get access to <strong>250GB</strong> of disk space for your analysis.</p>

<ol>
  <li>Open your browser. We recommend Chrome or Firefox (please don’t use Internet Explorer or Safari).</li>
  <li>Go to <a href="https://usegalaxy.eu">https://use<span class="notranslate">galaxy</span>.eu</a>
    <ul>
      <li>If you have previously registered on this server just log in:
        <ul>
          <li>On the top menu select: User -&gt; Login</li>
          <li>Enter your user/password</li>
          <li>Click Submit</li>
        </ul>
      </li>
      <li>If you haven’t registered on this server, you’ll need to do now.
        <ul>
          <li>On the top menu select: User -&gt; Register</li>
          <li>Enter your email, choose a password, repeat it and add a one word name (lower case)</li>
          <li>Click Submit</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<p>To familiarize with the <span class="notranslate">Galaxy</span> interface (e.g. working with histories, importing dataset),
we suggest to follow the <a href="https://galaxyproject.github.io/training-material/topics/introduction/tutorials/galaxy-intro-101/tutorial.html"><span class="notranslate">Galaxy</span> 101</a> tutorial.</p>

<h1 id="datasets">Datasets</h1>

<p>Input datasets used in this course are available:</p>
<ul>
  <li>at <a href="https://zenodo.org/record/3531578">Zenodo</a>, an open-access repository developed under the European OpenAIRE program and operated by CERN</li>
  <li>as <em>Shared Data Libraries</em> in <a href="https://usegalaxy.eu/library/list"><span class="notranslate">Galaxy</span></a>: <em><a href="https://usegalaxy.eu/library/list#folders/F3d08bb711e4e3b26"><span class="notranslate">Galaxy</span> courses / Sigu</a></em></li>
</ul>

<h2 id="get-data">Get data</h2>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-data-upload"><i class="fa fa-pencil" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Data upload</h3>

  <ol>
    <li>
      <p>Create a new history for this tutorial and give it a meaningful name (e.g. Clinical genomics)</p>

      <blockquote class="tip">

        <h3 id="tip-tip-creating-a-new-history"><i class="fa fa-lightbulb-o" aria-hidden="true"></i><span class="visually-hidden">tip</span> Tip: Creating a new history</h3>

        <p>Click the <i class="fa fa-plus" aria-hidden="true"></i><span class="visually-hidden">new-history</span> icon at the top of the history panel</p>

        <p>If the <i class="fa fa-plus" aria-hidden="true"></i><span class="visually-hidden">new-history</span> is missing:</p>
        <ol>
          <li>Click on the <i class="fa fa-cog" aria-hidden="true"></i><span class="visually-hidden"><span class="notranslate">galaxy</span>-gear</span> icon (<strong>History options</strong>) on the top of the history panel</li>
          <li>Select the option <strong>Create New</strong> from the menu</li>
        </ol>
      </blockquote>

      <blockquote class="tip">

        <h3 id="tip-tip-renaming-a-history"><i class="fa fa-lightbulb-o" aria-hidden="true"></i><span class="visually-hidden">tip</span> Tip: Renaming a history</h3>

        <ol>
          <li>Click on <strong>Unnamed history</strong> (or the current name of the history) (<strong>Click to rename history</strong>) at the top of your history panel</li>
          <li>Type the new name</li>
          <li>Press <kbd>Enter</kbd></li>
        </ol>
      </blockquote>
    </li>
    <li>
      <p>Import files from <a href="https://zenodo.org/record/3531578">Zenodo</a> or Shared Data Library:</p>

      <div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>https://zenodo.org/record/3531578/files/CNV_case.bam
https://zenodo.org/record/3531578/files/CNV_control.bam
https://zenodo.org/record/3531578/files/CNV_TruSeq_Chr2.<span class="notranslate">bed</span>
https://zenodo.org/record/3531578/files/HighQuality_<span class="notranslate">Reads</span>.fastq.gz
https://zenodo.org/record/3531578/files/LowQuality_<span class="notranslate">Reads</span>.fastq.gz
https://zenodo.org/record/3531578/files/Panel_alignment.bam
https://zenodo.org/record/3531578/files/Panel_target_regions.<span class="notranslate">bed</span>
https://zenodo.org/record/3531578/files/Sample1.all_exons.hg19.vcf
</code></pre></div>      </div>
      <blockquote class="tip">

        <h3 id="tip-tip-importing-data-via-links"><i class="fa fa-lightbulb-o" aria-hidden="true"></i><span class="visually-hidden">tip</span> Tip: Importing data via links</h3>

        <ul>
          <li>Copy the link location</li>
          <li>
            <p>Open the <span class="notranslate">Galaxy</span> Upload Manager (<i class="fa fa fa-upload" aria-hidden="true"></i><span class="visually-hidden"><span class="notranslate">galaxy</span>-upload</span> on the top-right of the tool panel)</p>
          </li>
          <li>Select <strong>Paste/Fetch Data</strong></li>
          <li>
            <p>Paste the link into the text field</p>
          </li>
          <li>
            <p>Press <strong>Start</strong></p>
          </li>
          <li><strong>Close</strong> the window</li>
        </ul>

        <p>By default, <span class="notranslate">Galaxy</span> uses the URL as the name, so rename the files with a more useful name.</p>

      </blockquote>

      <p>The same files may be available on the <span class="notranslate">Galaxy</span> server
through a <em>Shared Data Libraries</em> in 
<em><a href="https://usegalaxy.eu/library/list#folders/F3d08bb711e4e3b26"><span class="notranslate">Galaxy</span> courses/Sigu</a></em>.
You may prefer to import the data directly from there.</p>

      <blockquote class="tip">

        <h3 id="tip-tip-importing-data-from-a-data-library"><i class="fa fa-lightbulb-o" aria-hidden="true"></i><span class="visually-hidden">tip</span> Tip: Importing data from a data library</h3>

        <p>As an alte<span class="notranslate">rna</span>tive to uploading the data from a URL or your computer, the files may also have been made available from a <em>shared data library</em>:</p>

        <ul>
          <li>
            <p>Go into <strong>Shared data</strong> (top panel) then <strong>Data libraries</strong></p>
          </li>
          <li>
            <p>Find the correct folder (ask your instructor)</p>
          </li>
          <li>Select the desired files</li>
          <li>Click on the <strong>To History</strong> button near the top and select <strong>as Datasets</strong> from the dropdown menu</li>
          <li>In the pop-up window, select the history you want to import the files to (or create a new one)</li>
          <li>Click on <strong>Import</strong></li>
        </ul>
      </blockquote>

      <blockquote class="comment">
        <h3 id="comment-note"><i class="fa fa-commenting-o" aria-hidden="true"></i><span class="visually-hidden">comment</span> Note</h3>
        <p>All the files are based on <code class="highlighter-rouge">hg19</code> reference genome which is
available with pre-built indexes for widely used tools such as 
<em>bwa-mem</em> <strong>and</strong> <em>samtools</em> by selecting <code class="highlighter-rouge">hg19</code> version as an option under
<em>“(Using) reference genome”</em>).</p>
      </blockquote>
    </li>
    <li>
      <p>In case you import datasets from Zenodo, check that all datasets in your history
have their datatypes assigned correctly, and fix it when necessary.
For example, to assign <span class="notranslate">BED</span> datatype do the following:</p>

      <blockquote class="tip">

        <h3 id="tip-tip-changing-the-datatype"><i class="fa fa-lightbulb-o" aria-hidden="true"></i><span class="visually-hidden">tip</span> Tip: Changing the datatype</h3>
        <ul>
          <li>Click on the <i class="fa fa-pencil" aria-hidden="true"></i><span class="visually-hidden"><span class="notranslate">galaxy</span>-pencil</span> <strong>pencil icon</strong> for the dataset to edit its attributes</li>
          <li>In the central panel, click on the <i class="fa fa fa-database" aria-hidden="true"></i><span class="visually-hidden"><span class="notranslate">galaxy</span>-chart-select-data</span> <strong>Datatypes</strong> tab on the top</li>
          <li>Select <code class="highlighter-rouge"><span class="notranslate">bed</span></code></li>
          <li>Click the <strong>Change datatype</strong> button</li>
        </ul>
      </blockquote>
    </li>
    <li>
      <p>Rename the datasets</p>

      <p>For datasets uploaded via a link, <span class="notranslate">Galaxy</span> will use the link
as the dataset name. In this case you may rename datasets.</p>

      <blockquote class="tip">

        <h3 id="tip-tip-renaming-a-dataset"><i class="fa fa-lightbulb-o" aria-hidden="true"></i><span class="visually-hidden">tip</span> Tip: Renaming a dataset</h3>
        <ul>
          <li>Click on the <i class="fa fa-pencil" aria-hidden="true"></i><span class="visually-hidden"><span class="notranslate">galaxy</span>-pencil</span> <strong>pencil icon</strong> for the dataset to edit its attributes</li>
          <li>In the central panel, change the <strong>Name</strong> field</li>
          <li>Click the <strong>Save</strong> button</li>
        </ul>
      </blockquote>
    </li>
  </ol>

</blockquote>

<h1 id="next-generation-sequencing">Next Generation Sequencing</h1>

<p><em>Next (or Second) Generation Sequencing</em> (NGS/SGS) is an umbrella-term covering a number of approaches to <span class="notranslate">DNA</span> sequencing that have been developed after the first, widespread and for long time most commonly used Sanger sequencing.</p>

<p><em>NGS</em> is also known as <em>Massive Parallel Sequencing</em> (MPS), a term that makes explicit the paradigm shared by all these technologies, that is to sequence in parallel a massive library of spatially separated and clonally amplified <span class="notranslate">DNA</span> templates.</p>

<p>For a comprehensive review of the different <em>NGS</em> technologies see <a href="https://www.nature.com/articles/nrg.2016.49">Goodwin et al., 2016</a>, which also includes an introduction to the third generation methods allowing sequencing of long single-molecule <span class="notranslate">reads</span>.</p>

<h2 id="ngs-in-the-clinic">NGS in the clinic</h2>

<p>In the span of less than a decade, NGS approaches have pervaded clinical laboratories revolutionizing genomic diagnostics and increasing yield and timeliness of genetic tests.</p>

<p>In the context of disorders with a recognized strong genetic contribution such as neurogenetic diseases, <em>NGS</em> has been firmly established as the strategy of choice to rapidly and efficiently diagnose diseases with a Mendelian basis. A general diagnostic <span class="notranslate">workflow</span> for these disorders currently embraces different <em>NGS</em>-based diagnostic options as illustrated in <strong>Figure 1</strong>.</p>

<hr />

<p><img src="/clinical_genomics/images/ngs_neuro_diagnostics.png" alt="ngs_neuro_diagnostics" /></p>

<p><strong>Figure 1</strong>. General <span class="notranslate">workflow</span> for genetic diagnosis of neurological diseases. (*If considering high-yield single-gene testing of more than 1–3 genes by another sequencing method, note that next-generation sequencing is often most cost-effective. †Genetic counselling is required before and after all genetic testing; other considerations include the potential for secondary findings in genomic testing, testing parents if inheritance is sporadic or recessive, and specialty referral.) From <a href="https://www.thelancet.com/journals/laneur/article/PIIS1474-4422(19)30033-X/fulltext">Rexach et al., 2019</a></p>

<hr />

<p>Currently, most common <em>NGS</em> strategies in clinical laboratories are the so-called <strong>targeted sequencing</strong> methods that, as opposed to <strong>genome sequencing</strong> covering the whole genomic sequence, focus on a pre-defined set of regions of interest (the <strong>targets</strong>). The targets can be selected by <strong>hybrid capture</strong> or <strong>amplicon sequencing</strong>, and the target-enriched libraries is then sequenced. The most popular target designs are:</p>

<ul>
  <li><strong>gene panels</strong> where the coding exons of only a clinically-relevant group of genes are targeted</li>
  <li><strong>exome sequencing</strong> where virtually all the protein-coding exons in a genome are simultaneously sequenced</li>
</ul>

<h2 id="basics-of-ngs-bioinformatic-analysis">Basics of NGS bioinformatic analysis</h2>

<p>Apart from the different width of the target space in exome and gene panels, these two approaches usually share the same experimental procedure for NGS library preparation. After clonal amplification, the fragmented and adapter-ligated <span class="notranslate">DNA</span> templates are sequenced from both ends of the <em>insert</em> to produce short <span class="notranslate">reads</span> in opposite (<strong>forward</strong> and <strong>reverse</strong>) orientation (<strong>paired-end</strong> sequencing).</p>

<p>Bioinformatic analysis of NGS data usually follows a general three-step <span class="notranslate">workflow</span> to variant detection. Each of these three steps is marked by its “milestone” file type containing sequence data in different formats and metadata describing sequence-related information collected during the analysis step that leads to generation of that file.</p>

<table>
  <thead>
    <tr>
      <th>NGS <span class="notranslate">workflow</span> step</th>
      <th>File content</th>
      <th>File format</th>
      <th>File Size (individual exome)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Sample to <span class="notranslate">reads</span></td>
      <td>Unaligned <span class="notranslate">reads</span> and qualities</td>
      <td><strong>fastQ</strong></td>
      <td>gigabytes</td>
    </tr>
    <tr>
      <td><span class="notranslate">Reads</span> to alignments</td>
      <td>Aligned <span class="notranslate">reads</span> and metadata</td>
      <td><strong>BAM</strong></td>
      <td>gigabytes</td>
    </tr>
    <tr>
      <td>Alignments to variants</td>
      <td>Genotyped variants and metadata</td>
      <td><strong>VCF</strong></td>
      <td>megabytes</td>
    </tr>
  </tbody>
</table>

<p>Here are the different formats explained:</p>

<ul>
  <li><strong><a href="https://en.wikipedia.org/wiki/FASTQ_format">fastQ</a></strong> (sequence with quality): the <em>de facto</em> standard for storing the output of high-throughput sequencing machines
    <ul>
      <li>Usually not inspected during data analysis</li>
    </ul>
  </li>
  <li><strong><a href="https://samtools.github.io/hts-specs/SAMv1.pdf">BAM</a></strong> (binary sequence alignment/map): the most widely used TAB-delimited file format to store alignments onto a reference sequence
    <ul>
      <li>Aligned <span class="notranslate">reads</span></li>
    </ul>
  </li>
  <li><strong><a href="http://samtools.github.io/hts-specs/VCFv4.3.pdf">VCF</a></strong> (variant call format): the standard TAB-delimited format for genotype information associated with each reported genomic position where a variant call has been recorded</li>
</ul>

<p>Another useful file format is <a href="https://www.ensembl.org/info/website/upload/bed.html"><span class="notranslate">BED</span></a>, to list genomic regions of interest such as the exome or panel targets.</p>

<p>The steps of the <strong><em><span class="notranslate">reads</span>-to-variants</em></strong> <span class="notranslate">workflow</span> can be connected through a bioinformatic <strong>pipeline</strong> (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5429012/">Leipzig et al., 2017</a>), consisting in read alignments, post-alignment BAM processing and variant calling.</p>

<h2 id="alignment">Alignment</h2>

<p>As generated by the sequencing machines, <em>paired-end</em> <span class="notranslate">reads</span> are written to two <em>fastQ</em> files in which <em>forward</em> and <em>reverse</em> <span class="notranslate">reads</span> are stored separately together with their qualities. <em>FastQ</em> files are taken as input files by tools (the <strong>aligners</strong>) that align the <span class="notranslate">reads</span> onto a reference genome. One of the most used aligners is <a href="http://bio-bwa.sourceforge.net/">BWA</a> among the many that have been developed (Figure 2).</p>

<hr />

<p><img src="/clinical_genomics/images/aligners_timeline.png" alt="aligners_timeline" /></p>

<p><strong>Figure 2</strong>. Aligners timeline 2001-2012 (from <a href="https://academic.oup.com/bioinformatics/article/28/24/3169/245777">Fonseca et al., 2012</a>)</p>

<hr />

<p>During the bioinformatic process, <em>paired-end</em> <span class="notranslate">reads</span> from the two separate <em>fastQ</em> files are re-connected in the alignment, where it is expected that they will:</p>
<ul>
  <li>map to their correct location in the genome</li>
  <li>be as distant as the insert size of the fragment they come from</li>
  <li>be in opposite orientations
a combination which we refer to as <strong>proper pairing</strong>. All these data about <em>paired-end</em> <span class="notranslate">reads</span> <span class="notranslate">mapping</span> are stored in the BAM file and can be used to various purposes, from alignment quality assessment to structural variant detection.</li>
</ul>

<p>In <strong>Figure 3</strong>, the <a href="http://software.broadinstitute.org/software/igv/">Integrative Genomic Viewer (IGV)</a> screenshot of an exome alignment data over two adjacent <em>ASXL1</em> exons is shown. Pink and violet bars are <em>forward</em> and <em>reverse</em> <span class="notranslate">reads</span>, respectively. The thin grey link between them indicates that they are <em>paired-end</em> <span class="notranslate">reads</span>. The stack of <span class="notranslate">reads</span> is concentrated where exons are as expected in an exome, and the number of read bases covering a given genomic location <em>e</em> (depicted as a hill-shaped profile at the top of the figure) defines the <strong>depth of coverage (DoC)</strong> over that location:</p>

<p><em>DoC</em><sub>e</sub>=<em>number of read bases over e/genomic length of e</em></p>

<hr />

<p><img src="/clinical_genomics/images/coverage.png" alt="coverage" />
<strong>Figure 3</strong>. Exome data visualization by <a href="http://software.broadinstitute.org/software/igv/"><em>IGV</em></a></p>

<hr />

<h2 id="post-alignment-bam-processing">Post-alignment BAM processing</h2>

<p>Regarding post-alignment <em>pipelines</em>, the most famous for germline SNP and InDel calling is probably that developed as part of the GATK toolkit (<strong>Figure 4</strong>).</p>

<hr />

<p><img src="/clinical_genomics/images/gatk_germline_snps_indels.png" alt="gatk_germline_pipeline" /></p>

<p><strong>Figure 4</strong>. After-alignment pipeline for germline SNP and InDel variant calling according to <a href="https://software.broadinstitute.org/gatk/best-practices/workflow?id=11145">GATK Best Practices</a></p>

<hr />

<p>According to GATK best practices, in order to be ready for variant calling the BAM file should undergo the following processing:</p>
<ul>
  <li><a href="https://software.broadinstitute.org/gatk/documentation/tooldocs/4.0.4.0/picard_sam_markduplicates_MarkDuplicates.php">marking duplicate <span class="notranslate">reads</span></a> to flag (or discard) <span class="notranslate">reads</span> that are mere optical or PCR-mediated duplications of the actual <span class="notranslate">reads</span></li>
  <li><a href="https://software.broadinstitute.org/gatk/documentation/article?id=11081">recalibrating base quality scores</a> to correct known biases of the native base-related qualities
While GATK BAM processing is beyond doubt important to improve data quality, it has to be noticed that it is not needed to obtain variant calls and that non GATK-based pipelines may not use it or may use different quality reparametrization schemes. Duplicate flagging or removal is not recommended in <em>amplicon</em> sequencing experiments.</li>
</ul>

<h2 id="variant-calling">Variant calling</h2>

<p>The process of variant detection and genotyping is performed by <em>variant callers</em>. These tools use probabilistic approaches to collect evidence that non-reference read bases accumulating over a given locus support the presence of a variant, usually differing in algorithms, filtering strategies, recommendations (<a href="https://doi.org/10.1038/srep43169">Sandmann et al., 2017</a>). To be confident that a variant is a true event, its supporting evidence should be significantly stronger than chance; e.g. the C&gt;T on the left of the screenshot in Figure 5 is supported by all its position-overlapping <span class="notranslate">reads</span>, claiming for a variant. In contrast, the C&gt;A change on the right of the screenshot is seen only once over many <span class="notranslate">reads</span>, challenging its interpretation as a real variant. In fact, <span class="notranslate">DNA</span> variants that occur in germ cells (i.e., <strong>germline/constitutional variants</strong> that can be passed on to offspring) are either diploid/biallelic, so expected alte<span class="notranslate">rna</span>tive allele frequency is 50% for a heterozygous change. On the other hand, if only a smaller subset of aligned <span class="notranslate">reads</span> indicates variation, that could result from technology bias or be a <strong>mosaicism</strong>, i.e. an individual which harbour two or more populations of genetically distinct cells as a result of postzygotic mutation. Postzygotic <em>de novo</em> mutations may result in <strong>somatic mosaicism</strong> (potentially causing a less severe and/or variable phenotype compared with the equivalent constitutive mutation) <strong>and/or germline mosaicism</strong> (hence enabling transmission of a pathogenic variant from an unaffected parent to his affected offspring) (<a href="https://doi.org/10.1038/nrg3424">Biesecker et al., 2013</a>). To identify mosaicism, a probabilistic approach should consider deviation of the proband variant allele fraction (VAF, defined as the number of alte<span class="notranslate">rna</span>tive <span class="notranslate">reads</span> divided by the total read depth) from a binomial distribution centred around 0.5.</p>

<hr />

<p><img src="/clinical_genomics/images/igv_variant.png" alt="igv_screenshot_variant" /></p>

<p><strong>Figure 5</strong>. Variant visualization by <em>IGV</em></p>

<hr />

<p>The GATK variant calling pipeline first produces a <strong>genomic VCF (<a href="https://gatkforums.broadinstitute.org/gatk/discussion/4017/what-is-a-gvcf-and-how-is-it-different-from-a-regular-vcf">gVCF</a>)</strong>, whose main difference with <em>VCF</em> is that it records all sites in a target whether there is a variant or not, while <em>VCF</em> contains only information for variant sites, preparing multiple samples for <strong>joint genotyping</strong> and creation of a <strong>multi-sample</strong> <em>VCF</em> whose variants can undergo quality <strong>filtering</strong> in order to obtain the final set of quality-curated variants ready to be annotated.</p>

<p>In <span class="notranslate">downstream</span> analyses, annotations can be added to <em>VCF</em> files themselves or information in <em>VCF</em> files can be either annotated in TAB- or comma- deimited files to be visually inspected for <em>clinical</em> variant searching or used as input to <strong>prioritization</strong> programs.</p>

<h1 id="quality-control">Quality control</h1>

<p>Before data analysis, it is crucial to check the quality of the data at different levels of the analysis <span class="notranslate">workflow</span>:</p>
<ol>
  <li>Raw sequences in FASTQ format</li>
  <li>BAM files containing the sequences aligned to the reference genome</li>
  <li>Final list of variants if VCF format</li>
</ol>

<p>We will use several tools available at <a href="https://usegalaxy.eu">https://use<span class="notranslate">galaxy</span>.eu</a>
for checking the quality of data at each step of the analysis, as well as to evaluate the per-base coverage depth at specific genomic intervals</p>

<hr />
<p><img src="/clinical_genomics/images/qc_overview.png" alt="Quality control overview" />
<strong>Software for quality control</strong>, at each step of the analysis <span class="notranslate">workflow</span>.</p>

<hr />

<h2 id="quality-control-of-fastq-files">Quality control of FASTQ files</h2>

<p>We’ll use the <strong>FastQC</strong> software, with the FASTQ files available in the Shared Data Libraries: <em>HighQuality_<span class="notranslate">Reads</span>.fastq</em> and 
<em>LowQuality_<span class="notranslate">Reads</span>.fastq</em></p>

<p><em>FastQC</em> is relatively easy to use. A detailed help can be found in the <a href="http://www.bioinformatics.babraham.ac.uk/projects/fastqc/Help/">help manual</a>.</p>

<ul>
  <li>Copy the FASTQ file in your history from the <span class="notranslate">Galaxy</span> Shared Data Libraries</li>
  <li>Select <em>FastQC</em> from the left panel</li>
  <li>Select the FASTQ file as input</li>
  <li>Click <em>Execute</em></li>
</ul>

<p>The output of FASTQC consists of multiple modules analysing a specific aspect of the quality of the data.</p>

<p>The names of the modules are preceded by an icon that reflects the quality of the data. The icon indicates whether the results of the module are:</p>
<ul>
  <li>normal (green)</li>
  <li>slightly abnormal (orange)</li>
  <li>very unusual (red)</li>
</ul>

<p>These evaluations must be taken in the context of what you are expecting from your dataset. For FASTQC a <em>normal</em> includes random sequences with high diversity. If your experiment generates libraries biased in particular ways (e.g. low complexity libraries) you should consider the report with attention. In general, you should concentrate on the icons different from green and try to understand the reasons for this behaviour.</p>

<h3 id="sequence-quality-by-position">Sequence quality by position</h3>

<p>Phred scores represent base call quality. The higher the score the more reliable the base call. Often the quality of <span class="notranslate">reads</span> decreases over the length of the read. Therefore, it is common practice to plot the distribution of the Phred scores at each position using boxplots.</p>

<p>The average Phred score is depicted by the blue line, the median Phred score by the red line. The yellow boxes contain 50% of all Phred scores. The background of the graph divides the plot in three regions: good quality (green), reasonable quality (orange), poor quality (red; Phred score &lt; 20).</p>

<p>Below examples of datasets with high (left) and low (right) sequence quality</p>

<p><img src="/clinical_genomics/images/fastqc_sequence_quality.png" alt="High Quality reads" /></p>

<h3 id="check-overall-sequence-quality">Check overall sequence quality</h3>
<p>Calculates the average Phred score of each read and show a cumulative plot of the average qualities of all the <span class="notranslate">reads</span>.</p>

<h3 id="check-quality-per-tile">Check quality per tile</h3>
<p>This plot is specific for Illumina flowcells which are divided into tiles. To check whether there is a loss in quality associated with a specific area of the flowcell, FASTQC plots the average quality scores for each tile across all positions in the <span class="notranslate">reads</span>.</p>

<p>A good plot should be blue on all the area. Deviations from blue are positions where the quality was different from the average. Failures could be due to bubbles through the flowcells, presence of debris or, Illumina not patterned flow-cell, high density of clusters due to overlad. 
Failures affecting small areas of the flow-cell can be safely ignored.</p>

<h3 id="check-sequence-duplication">Check sequence duplication</h3>
<p>Due to random fragmentation, in a diverse library generated by shearing most fragments will occur only once. High level of duplication may indicate enrichment bias such as library contamination or PCR over-amplification.</p>

<p>The plot shows the relative number of <span class="notranslate">reads</span> with different degrees of duplication.</p>
<ul>
  <li>The red line represents the number of <strong>distinct</strong> sequences that are duplicated, where the percentage is relative to the total number of distinct sequences</li>
  <li>The blue line represents the counts of all the duplicated sequences, where the percentage is computed relative to the total number of <span class="notranslate">reads</span></li>
</ul>

<p>Most sequences should fall in the left part of the plot (low sequence duplication level).
Contaminants are visible as peaks in the blue line (high proportion of original sequences) but should be absent in the red line as they contribute as a minor fraction of the deduplicated dataset. If peaks are still present in the red line after deduplication, you may have a large number of different duplicated sequences which might indicate contamination.</p>

<h3 id="check-per-base-sequence-content">Check per base sequence content</h3>
<p>In presence of random sequences, the fraction of A, C, G and T should be the same on each position, producing four straight lines on this plot, one for each nucleotide. However you will often see several peaks for the first positions. This bias in the first positions arises from the protocol used to generate <span class="notranslate">RNA</span>-Seq libraries, either transposase based or priming with random examers. The bias is not due to a single sequence, but depends on different K-mers at the 5’ end of the <span class="notranslate">reads</span>, therefore cannot be removed by trimming a specific sequence from the 5’ end.
However, the presence of such bias, if limited to the first bases, do not affect <span class="notranslate">downstream</span> analyses.</p>

<h3 id="over-represented-sequences">Over-represented sequences</h3>

<p>This module checks for the presence of specific sequences which are over-represented in your library, i.e. <span class="notranslate">reads</span> that make a substantial fraction (&gt; 0.1%) of the total number of <span class="notranslate">reads</span>. In this module only the first 50bp are considered by FASTQC. Each overrepresented sequence is compared to a list of common contaminants to try to identify it.</p>

<p>You can see which position of the read is greatly affected (plot), and check the list of possible contaminants in the table with the list of sequences which make &gt; 0.1% of the total <span class="notranslate">reads</span>.</p>

<p>For <span class="notranslate">DNA</span>-Seq ideally you shouldn’t see any sequence in the table, even if a small fraction of adapter sequences can be observed, which can be easily removed by adding a step for adapter removal in the analysis pipeline. For <span class="notranslate">RNA</span>-Seq, highly abundant transcripts could be tracked as overrepresented sequences.</p>

<p>The presence of adapter sequences impacts the rate and speed of alignment.</p>

<h2 id="computation-of-per-base-coverage-depth-at-specific-genomic-intervals">Computation of per-base coverage depth at specific genomic intervals</h2>

<p>Commercial next-generation sequencing platform usually provide users with analysis programs that include tools for the identification of low coverage regions (for instance, target regions that have a coverage depth lower than 20x).</p>

<p>The present tutorial is aimed to show how to perform a custom coverage analysis
of NGS experiment(s) by using tools that are available in <span class="notranslate">Galaxy</span>.</p>

<p>Starting material:</p>
<ul>
  <li>Alignment (<em>bam</em>) file(s) on which you want to perform the coverage evaluation.</li>
  <li>A reference <em><span class="notranslate">bed</span></em> file listing the genomic regions for which you want to obtain coverage data. If you performed a targeted sequencing experiment by using commercial kits (either custom or from the catalogue), you should already have obtained a <em><span class="notranslate">bed</span></em> file listing the target regions: it should be the file you want to use.</li>
</ul>

<blockquote>
  <blockquote class="comment">
    <h3 id="comment-bed-format-specifications"><i class="fa fa-commenting-o" aria-hidden="true"></i><span class="visually-hidden">comment</span> <span class="notranslate">BED</span> format specifications</h3>
    <p><strong><span class="notranslate">BED</span> files</strong> are tab-delimited files with one line for each genomic region.
The first 3 fields (columns) are required:</p>
    <ol>
      <li>chromosome</li>
      <li>the starting position</li>
      <li>the ending position</li>
    </ol>

    <p>Further columns may be present but are optional.
Additional details may be found here: <a href="https://genome.ucsc.edu/FAQ/FAQformat.html#format1">UCSC <span class="notranslate">BED</span> format specifications</a></p>

    <p>Please be aware that in <span class="notranslate">BED</span> files the description of genomic regions follows the “0-start, half-open” coordinate system. Further details may be found here: <a href="http://genome.ucsc.edu/blog/the-ucsc-genome-browser-coordinate-counting-systems/">the “0-based, half-open” UCSC Genome Browser Coordinate Counting Systems</a>. Practically speaking, it means that the starting position is diminished by 1 bp with respect to the actual position. For instance, the region “chr2 50149071 50149399” in a <em><span class="notranslate">bed</span></em> file corresponds to the genomic interval from position 50149072 (included) to position 50149399 (included) on chromosome 2 (when the first base of the chromosome is defined as position 1). If you want to indicate a single base position in a <em><span class="notranslate">bed</span></em> file, it should be written like this: “chr2 50149071 50149072” .</p>
  </blockquote>
</blockquote>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-compute-per-base-coverage-depth-with-bedtools"><i class="fa fa-pencil" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Compute per base coverage depth with <span class="notranslate">BED</span>tools</h3>
  <p>Before starting, you have to upload the files you need for the analysis,
   following standard <span class="notranslate">Galaxy</span> procedure.</p>

  <p>You may use files provided as examples with this tutorial and called
   <code class="highlighter-rouge">Panel_alignment.bam</code> and <code class="highlighter-rouge">Panel_Target_regions.<span class="notranslate">bed</span></code>.</p>

  <p>Please check that uploaded file datatypes (formats) are properly recognized by
   selecting <code class="highlighter-rouge">edit attributes</code> (i.e. the pencil sign in correspondence of each file
   you can find in your history) (indicated by the red arrow in figure 1)
   and then the tab datatypes (the blue arrow in figure 1).
   If the datatype is wrong, select the correct one from the drop-down list
   and press the <code class="highlighter-rouge">change datatype</code> button (the green arrow in figure 1).</p>

  <hr />
  <p><img src="/clinical_genomics/images/cov_fig1.png" alt="Figure 1" />
   <strong>Figure 1</strong></p>

  <hr />

  <p>Once ready, you can select the tool named <code class="highlighter-rouge"><span class="notranslate">bed</span>tools Compute both the depth and
   breadth of coverage</code> in the <code class="highlighter-rouge">Operate on Genomic Intervals</code> section
   (see the red arrow in figure 2).</p>

  <ol>
    <li>Select the <em><span class="notranslate">bed</span></em> file listing the target regions as “file A” (blue arrow in figure 2)
and the <em>bam</em> file(s) you want to analyze as “file B” (green arrow in figure 2)
(they should be listed in the drop-down menu if they have the correct format).
You may analyze one or more <em>bam</em> files in a single run.</li>
    <li>If you want to analyze two or more .bam files, you can further choose if you want
all the results in a single file or one output file per input “file B” by selecting
the desired option under the <code class="highlighter-rouge">Combined or separate output files</code> menu.</li>
    <li>Select “Yes” for the option <code class="highlighter-rouge">Report the depth at each position in each A feature</code>
  (yellow arrow in figure 2) and check that all the other options are set to “No”.</li>
    <li>
      <p>Star (Execute) the analysis.</p>

      <p><img src="/clinical_genomics/images/cov_fig2.png" alt="Figure 2" />
<strong>Figure 2</strong></p>
    </li>
  </ol>

  <hr />

  <p>Output file, which will be called “coverage_depth.<span class="notranslate">bed</span>” from now on, 
   will contain all the fields of the original target_regions.<span class="notranslate">bed</span> file plus
   two further columns:</p>
  <ol>
    <li>the first value indicates a specific base within the reported genomic interval.
For instance, if the genomic interval described by the first 3 field is
“chr2 50149071 50149072” and the first new field reports the number 1000,
it means that the coverage value refers to nucleotide 50150071
(i.e.: 50149071 + 1000) on chromosome 2;</li>
    <li>the second value indicates the depth of coverage for the defined base.</li>
  </ol>
</blockquote>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-sort-files"><i class="fa fa-pencil" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Sort files</h3>
  <p>Since entries in the “coverage_depth.<span class="notranslate">bed</span>” may not be in the desired order, you can sort it by genomic positions.
   For this purpose you may want to use the <code class="highlighter-rouge">Sort</code> tool in the <code class="highlighter-rouge">Text Manipulation</code> section (check out the blue arrow in figure 3).</p>

  <p>You may sequentially sort on different columns:</p>
  <ol>
    <li>first you can sort by chromosome by selecting column 1 (green arrow in figure 3) in “ascending order” and selecting the “flavor” <code class="highlighter-rouge">Natural/Version sort (-V)</code>, which allows for sorting chromosomes in their “natural” order (with alphabetical order chr10 will be right after chr1, chr2 after chr19 and so on);</li>
    <li>after inserting a new column section (red arrow in figure 3), you can sort by column 2 in “ascending order” with <code class="highlighter-rouge">Fast numeric sort (-n)</code>;</li>
    <li>after inserting a further column section, you can sort by column 3 in “ascending order” with <code class="highlighter-rouge">Fast numeric sort (-n)</code>;</li>
    <li>after inserting a final column section, you can sort by column 3 in “ascending order” with <code class="highlighter-rouge">Fast numeric sort (-n)</code>.</li>
  </ol>

  <hr />
  <p><img src="/clinical_genomics/images/cov_fig3.png" alt="Figure 3" />
   <strong>Figure 3</strong></p>

  <hr />

  <p>The obtained output file, which will be called “sorted_coverage_depth.<span class="notranslate">bed</span>”
   from now on, will be sorted first by chromosome, then by starting position,
   by ending position and by the actual position of the specific base in the
   considered genomic interval.</p>
</blockquote>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-remove-duplicate-rows"><i class="fa fa-pencil" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Remove duplicate rows</h3>
  <p>If your file contains duplicated lines you may want to remove them for further processing.
   For this purpose you can use the <code class="highlighter-rouge">Unique lines assuming sorted input file</code> tool in the <code class="highlighter-rouge">Text Manipulation</code> section.</p>
</blockquote>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-some-manipulation-of-the-bed-file"><i class="fa fa-pencil" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Some manipulation of the <em><span class="notranslate">bed</span></em> file</h3>
  <p>You may follow the following steps to manipulate the “sorted_coverage_depth.<span class="notranslate">bed</span>” and to obtain a <em><span class="notranslate">bed</span></em> file listing the exact base position to which each coverage value is referred.
   For instance instead of having “chr2 50149071 50149399 NRXN1 1 2335” in the first row of your file, you will get “chr2 50149071 50149072 NRXN1 2335”.</p>

  <p>These steps will add further columns at the end of each line defining the base position with the “0-start, half-open” coordinate system.</p>

  <ol>
    <li>Select the <code class="highlighter-rouge">Compute an <span class="notranslate">expression</span> on every row</code> tool in the <code class="highlighter-rouge">Text Manipulation</code> section (indicated by the blue arrow in figure 4);</li>
    <li>add the following <span class="notranslate">expression</span> “c2+c5-1” to obtain the sum of the values in columns 2 and 5 minus 1 (it will be used as the new starting position in the final file);</li>
    <li>select the file “sorted_coverage_depth.<span class="notranslate">bed</span>”;</li>
    <li>select “yes” to <code class="highlighter-rouge">round Results?</code> (green arrow in figure 4);</li>
    <li>execute;</li>
    <li>you can rename the output as “temp1_coverage_depth.<span class="notranslate">bed</span>”;</li>
    <li>select the <code class="highlighter-rouge">Compute an <span class="notranslate">expression</span> on every row</code> tool in the <code class="highlighter-rouge">Text Manipulation</code> section;</li>
    <li>add the following <span class="notranslate">expression</span> “c2+c5” to obtain the sum of the values in columns 2 and 5 (it will be used as the new ending position in the final file). You can also use the <span class="notranslate">expression</span> ;</li>
    <li>select the file “temp1_coverage_depth.<span class="notranslate">bed</span>”;</li>
    <li>select “yes” to <code class="highlighter-rouge">round Results?</code>;</li>
    <li>execute;</li>
    <li>you can rename the output as “temp2_coverage_depth.<span class="notranslate">bed</span>”;</li>
    <li>select the <code class="highlighter-rouge">Table Compute</code> tool in the <code class="highlighter-rouge">Text Manipulation</code> section (indicated by the blue arrow in figure 5);</li>
    <li>select the file “temp2_coverage_depth.<span class="notranslate">bed</span>”;</li>
    <li>select the option <code class="highlighter-rouge">Drop, keep or duplicate rows and columns</code> from the drop-down menu <code class="highlighter-rouge">Type of table operation</code> (indicated by the green arrow in figure 5);</li>
    <li>fill the field <code class="highlighter-rouge">List of columns to select</code> with “1,7,8,4,6” (the red arrow in figure 5);</li>
    <li>unselect all the other options;</li>
    <li>execute;</li>
    <li>set the output file datatype to <em><span class="notranslate">bed</span></em>;</li>
    <li>you can rename the output as “final_coverage_depth.<span class="notranslate">bed</span>”.</li>
  </ol>

  <hr />
  <p><img src="/clinical_genomics/images/cov_fig4.png" alt="Figure 4" />
   <strong>Figure 4</strong></p>

  <p><img src="/clinical_genomics/images/cov_fig5.png" alt="Figure 5" />
   <strong>Figure 5</strong></p>

  <hr />
</blockquote>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-select-positions-with-low-coverage-depth"><i class="fa fa-pencil" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Select positions with low coverage depth</h3>
  <p>The following procedure can be used to obtain a <em><span class="notranslate">bed</span></em> file listing base positions with a coverage depth lower than a certain threshold (for instance 20x).</p>

  <ol>
    <li>Select the <code class="highlighter-rouge">Filter</code> tool in the <code class="highlighter-rouge">Filter and Sort</code> section (indicated by the blue arrow in figure 6);</li>
    <li>select the file “final_coverage_depth.<span class="notranslate">bed</span>”;</li>
    <li>add the following <span class="notranslate">expression</span> “c5&lt;20” to filter all positions with a coverage depth lower than (green arrow in figure 6)(“c5” stands for the fifth column, in this case reporting the coverage depth);</li>
    <li>execute.</li>
  </ol>

  <hr />
  <p><img src="/clinical_genomics/images/cov_fig6.png" alt="Figure 6" />
   <strong>Figure 6</strong></p>

  <hr />

  <p>The output file, which will be called “low_coverage_depth.<span class="notranslate">bed</span>” from now on, will only list all the positions with a depth lower than 20x.</p>
</blockquote>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-merge-low-coverage-regions"><i class="fa fa-pencil" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Merge low coverage regions</h3>
  <p>If you want to merge the positions with low coverage depth in larger genomic intervals to be used for further analyses (i.e.: Sanger sequencing of regions not covered by your NGS experiment), you may want to use the <code class="highlighter-rouge"><span class="notranslate">bed</span>tools MergeBED</code> tool in the <code class="highlighter-rouge">Operate on Genomic Intervals</code> section (see the blue arrow in figure 7).</p>

  <ol>
    <li>Select the file “low_coverage_depth.<span class="notranslate">bed</span>”;</li>
    <li>set the maximum distance between features (i.e.: the different positions listed in your file) allowed for features to be merged (green arrow in figure 7): if it is 0 only overlapping and/or book-ended features are merged, while if it is set to 10 (or any other different positive integer of your choice), features at the maximum distance of 10 bases will be merged;</li>
    <li>if you want, you may apply some operations to certain columns to get further information in your output file. For instance you may:
      <ol>
        <li>click on “Insert Applying operations to columns from merged intervals” (red arrow in figure 7),</li>
        <li>specify the column on which you want to perform the operation (in this case column 5),</li>
        <li>and select the operation from the drop-down list(in this case “Min”, which calculates the minimum value of coverage depth among all the positions that will be merged in a single interval) (yellow arrow in figure 7);</li>
      </ol>
    </li>
    <li>you may add as many operations as you need. In this example we will also calculate the maximum value of coverage depth;</li>
    <li>execute.</li>
  </ol>

  <hr />
  <p><img src="/clinical_genomics/images/cov_fig7.png" alt="Figure 7" />
   <strong>Figure 7</strong></p>

  <hr />
  <p>The output file will have the following fields (columns): chromosome, starting and ending positions of low coverage regions, the minimum and the maximum coverage depth in each region.</p>

  <blockquote class="warning">
    <h3 id="warning-bed-files-may-have-different-columns"><i class="fa fa-warning" aria-hidden="true"></i><span class="visually-hidden">warning</span> <span class="notranslate">BED</span> files may have different columns</h3>
    <p>Please be aware that the columns to use for calculations may be different
compared to the example here considered, depending on the amount of columns
of your <em><span class="notranslate">bed</span></em> files.</p>
  </blockquote>

  <blockquote class="warning">
    <h3 id="warning-preview-of-bed-files"><i class="fa fa-warning" aria-hidden="true"></i><span class="visually-hidden">warning</span> Preview of <span class="notranslate">BED</span> files</h3>
    <p>Please be aware that the <span class="notranslate">Galaxy</span> preview of your file shows a header row that
does not properly define columns in your files
(it is just a standard header for the UCSC <span class="notranslate">bed</span> format).</p>
  </blockquote>

</blockquote>

<h3 id="final-notes">Final notes</h3>
<p>The procedures listed above are to be taken as examples of the possible operations that can be performed on <span class="notranslate">bed</span> files with <span class="notranslate">bed</span>tools (you may check out their website to get further information:
<a href="https://bedtools.readthedocs.io/en/latest/content/bedtools-suite.html"><span class="notranslate">BED</span>tools</a>) ad text manipulation tools available on <span class="notranslate">Galaxy</span>.</p>

<p>Furthermore, please be aware that the tool <code class="highlighter-rouge"><span class="notranslate">bed</span>tools Compute both the depth and breadth of coverage</code> does not perform any filtering based on read quality: if your are interested in that aspect you may want to rely on different tools.</p>

<h1 id="variant-calling-and-classification">Variant calling and classification</h1>

<p>After the generation of a high-quality set of mapped read pairs, we can proceed to call different classes of <span class="notranslate">DNA</span> variants. To this aim, the tools <strong>HaplotypeCaller</strong> and <strong>MuTect2</strong> from <strong><a href="https://gatk.broadinstitute.org/hc/en-us">GATK toolkit</a></strong> are a dedicated solution for <span class="notranslate">DNA</span> variant identification at germinal- and somatic-level. They can:</p>

<ul>
  <li>Determine haplotypes by local assembly of the genomic regions in which the samples being analyzed show substantial evidence of variation relative to the reference;</li>
  <li>Evaluate the evidence for haplotypes and variant alleles;</li>
  <li>Assigning per-sample genotypes.</li>
</ul>

<blockquote>
  <h3 id="hands_on-hands-on-variant-calling"><i class="fa fa-pencil" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Variant calling.</h3>
  <p>You may use files provided as examples with this tutorial and called
   <code class="highlighter-rouge">Panel_alignment.bam</code> and <code class="highlighter-rouge">Panel_Target_regions.<span class="notranslate">bed</span></code>.</p>

  <ol>
    <li>Run <strong>HaplotypeCaller</strong> <i class="fa fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> restricting the search space on target regions with “-L” option to reduce computational burden.</li>
  </ol>

  <p>In case of analyzing a single sample:</p>

  <p><code class="highlighter-rouge">gatk HaplotypeCaller -I Panel_alignment.bam -O Sample1.all_exons.hg19.vcf -L Panel_target_regions.<span class="notranslate">bed</span> -R HSapiensReference_genome_hg19.fasta</code></p>

  <p>In case of analyzing a cohort (e.g. family) of samples, the most efficient way to identify variants is a multi-step process, running HaplotypeCaller per-sample to generate many intermediate gVCF files, merge them, and then calling genotypes on the whole group, based on the alleles that were observed at each site:</p>

  <p><code class="highlighter-rouge">gatk  HaplotypeCaller -I Panel_alignment.bam -O Sample1.all_exons.hg19.vcf -R HSapiensReference_genome_hg19.fasta -L Panel_target_regions.<span class="notranslate">bed</span> -ERC GVCF</code></p>

  <p>To obtain genotypes for all the cohort provide a combined multi-sample GVCF and then use it to calculate likelihoods:</p>

  <ul>
    <li>
      <p><code class="highlighter-rouge">gatk CombineGVCFs --variant Sample1.all_exons.hg19.vcf --variant Sample2.all_exons.hg19.vcf -O cohort.all_exons.hg19.g.vcf -L Panel_target_regions.<span class="notranslate">bed</span> -R HSapiensReference_genome_hg19.fasta</code></p>
    </li>
    <li>
      <p><code class="highlighter-rouge">gatk GenotypeGVCFs -V cohort.all_exons.hg19.g.vcf -O cohort_genotyped.all.exons.vcf -L Panel_target_regions.<span class="notranslate">bed</span> -R HSapiensReference_genome_hg19.fasta</code></p>
    </li>
  </ul>

  <p>The genotyped SNV/INDELs are then stored in a VCF file to be functionally annotated.</p>

  <ol>
    <li>Run <strong>Mutect2</strong> <i class="fa fa-wrench" aria-hidden="true"></i><span class="visually-hidden">tool</span> restricting the search space on target regions with “-L” option to reduce computational burden.
The first step is needed to create an inte<span class="notranslate">rna</span>l database of controls (i.e. <strong>Panel Of Normals</strong> - PoN) to reduce bias for somatic calls. It runs on a single sample at time:</li>
  </ol>

  <ul>
    <li><code class="highlighter-rouge">gatk Mutect2 -R HSapiensReference_genome_hg19.fasta -L Panel_target_regions.<span class="notranslate">bed</span> -I Panel_alignment_normal1.bam -O normal_genotyped1.vcf</code></li>
    <li><code class="highlighter-rouge">gatk Mutect2 -R HSapiensReference_genome_hg19.fasta -L Panel_target_regions.<span class="notranslate">bed</span> -I Panel_alignment_normal2.bam -O normal_genotyped2.vcf</code></li>
  </ul>

  <p>Then use GATK’s <em>CreateSomaticPanelOfNormals</em> tool to generate the PoN:</p>

  <ul>
    <li><code class="highlighter-rouge">gatk GenomicsDBImport -L Panel_target_regions.<span class="notranslate">bed</span> -R HSapiensReference_genome_hg19.fasta --genomicsdb-workspace-path PoN_db -V normal_genotyped1.vcf -V normal_genotyped2.vcf</code></li>
    <li>
      <p><code class="highlighter-rouge">gatk CreateSomaticPanelOfNormals -R HSapiensReference_genome_hg19.fasta -V gendb://PoN_db -O panel_of_normals.vcf</code></p>

      <blockquote class="comment">
        <h3 id="comment-note-1"><i class="fa fa-commenting-o" aria-hidden="true"></i><span class="visually-hidden">comment</span> Note</h3>
        <p>The –genomicsdb-workspace-path must point to a non-existent or empty directory.</p>
      </blockquote>
    </li>
  </ul>

  <p>Then, to effectively call somatic mutations, we can use variants contained in the <strong>PoN</strong> and/or other public repositories  (e.g. by means of the option <em>–germline-resource</em>, using a VCF file containing frequencies of germline variants in the general population) to exclude germline variation. Finally, to properly classify somatic variants, we apply <em>FilterMutectCalls filtering</em>, which produces the final subset annotated VCF file. To this aim, we can run the following commands:</p>

  <ul>
    <li>
      <p><code class="highlighter-rouge">gatk Mutect2 -R HSapiensReference_genome_hg19.fasta -I Panel_alignment.bam --germline-resource af-only-gnomad.vcf --panel-of-normals panel_of_normals.vcf -O somatic_genotyped_unfiltered.vcf</code></p>
    </li>
    <li>
      <p><code class="highlighter-rouge">gatk FilterMutectCalls -R HSapiensReference_genome_hg19.fasta -V somatic_genotyped_unfiltered.vcf -O somatic_genotyped_filtered.vcf</code></p>
    </li>
  </ul>

</blockquote>

<h1 id="variant-annotation">Variant annotation</h1>

<p>Once called, variants (SNPs and InDels) need to be annotated.</p>

<p>We want to know for example if a variant is located in a gene, if it’s in the coding portion of that gene, if it causes an aminoacid substitution, if that substitution is deleterious for the encoded protein function.</p>

<p><strong>Variant annotation</strong> is the process of attaching technical and/or biological information from multiple available source (e.g. <strong>public databases</strong>) to variants</p>

<hr />
<h2 id="gene-model">Gene model</h2>

<p>The choice of gene model is essential for variant <span class="notranslate">downstream</span> variant annotation: it describe genomic positions of genes and each exon-intron exact locations</p>

<p>Different gene models can give different annotations:
<img src="/clinical_genomics/images/brca1_var.jpg" alt="BRCA1" /></p>

<p><strong>Figure 1.</strong> Variant indicated by the red dashed line can be annotated as <em>intronic</em> or <em>exonic</em> (on one of the UCSC transcript variants), depending on the adopted gene model:</p>

<ul>
  <li><a href="https://www.ncbi.nlm.nih.gov/refseq/">RefSeq</a></li>
  <li><a href="https://www.ensembl.org/Homo_sapiens/Info/Index">Ensembl</a></li>
  <li><a href="https://www.gencodegenes.org/human/">Gencode</a></li>
</ul>

<hr />
<h2 id="sequence-variant-nomenclature">Sequence variant nomenclature</h2>

<p>Variant nomenclature should be described univocally:</p>

<ul>
  <li><a href="https://varnomen.hgvs.org/">HGVS</a></li>
  <li><a href="https://www.genenames.org/">HGMC</a></li>
</ul>

<h2 id="variant-class">Variant class</h2>

<ul>
  <li><a href="http://www.sequenceontology.org/">Sequence Ontology</a></li>
  <li><img src="/clinical_genomics/images/seqOnt.png" alt="Sequence Ontology" /></li>
</ul>

<h2 id="population-sequencing-db">Population sequencing db</h2>

<ul>
  <li><a href="https://gnomad.broadinstitute.org/">gnomAD</a></li>
  <li><a href="http://exac.broadinstitute.org/">ExAC</a></li>
  <li><a href="https://www.internationalgenome.org/">1000 Genomes Project</a></li>
  <li><a href="https://evs.gs.washington.edu/EVS/">NHLBI-ESP 6500 exomes</a></li>
  <li><a href="https://www.ncbi.nlm.nih.gov/snp/">dbSNP</a></li>
</ul>

<h2 id="variant-diseasegene-disease-db">Variant-disease/gene-disease db</h2>

<ul>
  <li><a href="http://www.hgmd.cf.ac.uk/ac/index.php">Human Gene Mutation Database</a></li>
  <li><a href="https://www.ncbi.nlm.nih.gov/clinvar/">clinically relevant variants known in a gene</a></li>
  <li><a href="http://simple-clinvar.broadinstitute.org/">Simple ClinVar</a></li>
  <li>
    <p><a href="https://www.omim.org/">Online Mendelian Inheritance in Man</a></p>
  </li>
  <li><a href="https://sites.google.com/site/jpopgen/dbNSFP"><strong>dbNSFP</strong></a>, a big database of curated annotations and precomputed functional predictions for all potential non-synonymous and splice-site single-nucleotide variants in the human genome</li>
</ul>

<h2 id="annotation-software-and-tools">Annotation Software and tools</h2>

<ul>
  <li><a href="https://www.ensembl.org/info/docs/tools/vep/index.html">Variant Effect Predictor</a></li>
  <li><a href="http://annovar.openbioinformatics.org/en/latest/">ANNOVAR</a></li>
  <li><a href="http://snpeff.sourceforge.net/">Single Nucleotide Polymorphism Effect</a></li>
  <li>
    <p><a href="http://grass.cgs.hku.hk/limx/kggseq/">KGGSeq</a></p>
  </li>
  <li>Web Interface:
    <ul>
      <li><a href="http://wannovar.wglab.org">wAnnovar</a></li>
      <li><a href="http://grch37.ensembl.org/Homo_sapiens/Tools/VEP">VEP</a></li>
    </ul>
  </li>
</ul>

<hr />
<h2 id="annotation-and-filtering-with-wannovar">Annotation and filtering with wANNOVAR</h2>

<p>The web tool <a href="http://wannovar.wglab.org/index.php">wANNOVAR</a> allows for rapid annotation of your variants and for some basic filtering steps to find disease genes.
It is based on its command line counterpart <a href="http://annovar.openbioinformatics.org/">ANNOVAR</a>, but it is more user-friendly since it does not require any programming skills.</p>

<p>The output consist in tabular text files that can be easily manipulated with Excel or other sp<span class="notranslate">reads</span>heet programs.</p>

<p>The annotation is performed against some of the most commonly used databases: RefSeq, UCSC Known, ENSEMBL/Genecode, dbSNP, ClinVar, 1000genomes, ExAC, ESP6500, gnomAD (minor allele frequencies in different populations are reported) and various precalculated prediction scores for any possible single nucleotide variant in coding regions (see <a href="https://sites.google.com/site/jpopgen/dbNSFP">dbNSFP</a>).</p>

<p>The gene-based annotation results in a single row for each input variant: only the most deleterious consequence is reported (i.e.: if a certain variant may result to be missense for one transcript and nonsense for a second transcript, only the latter consequence will be reported).</p>

<p>Unfortunately, unlike the command line version, wANNOVAR does neither allow for the use of custom annotation databases, nor for the selection of different pubblicly available databases.</p>

<p>To annotate your file with wANNOVAR you need to provide your email address, to be notified when the annotation is complete, and just upload your input file (or paste a series of variant in the designated field). Results are usually ready within minutes.
<img src="/clinical_genomics/images/wann_fig1.png" alt="Figure 1" /></p>

<p>You will get both <em>csv</em> files or <em>txt</em> files (which can be saved as they are by clicking on the specific link, right-clicking in any point of the page and selecting <code class="highlighter-rouge">Save as</code>). They can be both opened with Excel or other sp<span class="notranslate">reads</span>heet programs (concerning <em>csv</em> files, please ensure that comma are set as default list separator/delimiter in your version of Excel).</p>

<p>You will also get both <code class="highlighter-rouge">exome summary results</code> (only conding variants are included) and <code class="highlighter-rouge">genome summary results</code> (all variants included).</p>

<p>You can also provide a list of Disease or Phenotype Terms that the program can use for filtering your results (only for single sample <code class="highlighter-rouge">vcf</code> files).
<img src="/clinical_genomics/images/wann_fig2.png" alt="Figure 2" /></p>

<p>Finally, there are some Parameter Settings that can be modified:</p>
<ul>
  <li>Result duration: it can now only be set to “1 day”, since your files will be automatically removed after 24 hours.</li>
  <li>Reference genome: you can choose between hg19 (GRCh37) and hg38 (GRCh38).</li>
  <li>Input Format: you can upload not only <em>vcf</em> files, but also other kinds of variant files.</li>
  <li>Gene Definition: the database you want to use for gene function annotation. Three oprtions are available: RefSeq, UCSC Known, ENSEMBL/Gencode</li>
  <li>Individual analysis: the “Individual analysis” option allows you to perform further filtering steps (based on the Disease/Phenotype terms or the Disease Model) on a single sample (if you upload a multisample <em>vcf</em> only the first sample will be considered); the “All Annotaions” option will annotate all variants in your multisample <em>vcf</em>, maintaining the original columns of your <em>vcf</em> as the last columns of your output file.</li>
  <li>Disease Model: this options allows for some basic filtering of your variants based on the expected mechanism of inheritance. In mainly consider frequencies, sample genotypes and consequences at level of genic function. FIltering step are summarized among the results and they are only performed on a single sample: the program does not perform any multisample evaluation (i.e.: variant segregation in a trio) and cannot classify any variant as de novo even if you provide a multisample <em>vcf</em> with parental genotypes.</li>
</ul>

<h2 id="clinical-databases-for-further-manual-variant-annotation">Clinical databases for further manual variant annotation</h2>

<p>Once you have obtained a file with the annotation of your variants, you might find useful to annotate also the involved genes, in order to know, for instance, the list of diseases that may be associated with them.</p>

<p>Some databases that can the jb are the following:</p>
<ol>
  <li>The gene2phenotype dataset (<a href="https://www.ebi.ac.uk/gene2phenotype/disclaimer">G2P</a>) integrates data on genes, variants and phenotypes for example relating to developmental disorders. In the “Download” section you will find both databases of genes related to cancer and to developmental disorders. Those files report for each gene listed: the OMIM number, the associated disease name, the disease OMIM number, the disease category (you can fing more details in the “Terminology” section), whether the disease is caused by biallelic or monoallelic variants (“allelic requirement”), the expected category of variant to be causative of the disease, and a few other details.</li>
  <li>In the “Download” section of the <a href="https://www.omim.org/downloads/">OMIM database</a>, if you register for research and educational use, you may obtain different lists of OMIM genes and their associated phenotypes.</li>
  <li>Among the files available for download from the <a href="https://gnomad.broadinstitute.org/downloads#constraint">gnomAD database</a>, you may get per-gene constraint scores (for further details, please check the paper by the Exome Aggregation Consortium on “Nature. 2016 Aug 18; 536(7616):285–291.”). Those score may indicate if a specific gene is expected to be intolerant to loss-of-function variants (pLI) (haploinsufficiency), or if it is predicted to be associate to recessive diseases.</li>
</ol>

<p>In the end, you can add these annotations to your wANNOVAR files by using the <code class="highlighter-rouge">VLOOKUP</code> function in Excel.</p>

<h1 id="variant-prioritization">Variant prioritization</h1>

<p>Once annotated, variants need to be filtered and prioritized</p>

<ul>
  <li>WES: Tens of thousands</li>
  <li>WGS: Millions</li>
</ul>

<p><strong>No universal filters, they depend on the experimental features</strong></p>

<h2 id="variant-impact">Variant impact</h2>

<p>First of all you usually want to filter variants by consequence on the encoded protein, keeping those which have an higher impact on protein:</p>

<ul>
  <li>Missense</li>
  <li>Nonsense</li>
  <li>Splice sites</li>
  <li>Frameshift indels</li>
  <li>Inframe indels</li>
</ul>

<h2 id="variant-frequency">Variant frequency</h2>

<ul>
  <li>Common variants are unlikely associated with a clinical condition</li>
  <li>A rare variant will probably have a higher functional effect on the protein</li>
  <li>Frequency cut-off have to be customized on each different case</li>
  <li>Typical cut-offs: 1% - 0.1%</li>
  <li>Allele frequencies may differ a lot between different populations</li>
</ul>

<h2 id="variant-effect-prediction-tools">Variant effect prediction Tools</h2>

<ul>
  <li>Tools that predict consequences of amino acid substitutions on protein function</li>
  <li>
    <p>They give a score and/or a prediction in terms of “Tolerated”, “Deleterious” (SIFT) or “Probably Damaging”, “Possibly Damaging”, “Benign” (Polyphen2)</p>

    <ul>
      <li>fitCons</li>
      <li>GERP++</li>
      <li>SIFT</li>
      <li>PolyPhen2</li>
      <li>CADD</li>
      <li>DANN</li>
      <li>Condel</li>
      <li>fathmm</li>
      <li>MutationTaster</li>
      <li>MutationAssessor</li>
      <li>REVEL</li>
    </ul>
  </li>
</ul>

<h2 id="acmgamp-2015-guidelines">ACMG/AMP 2015 guidelines</h2>

<p>The <em>American College of Medical Genetics</em> and the <em>Association for Molecular Pathology</em> published guidelines for the interpretation of sequence variants in May of 2015 <a href="https://www.nature.com/articles/gim201530">(Richards S. et al, 2015)</a>. This report describes updated standards and guidelines for classifying sequence variants by using criteria informed by expert opinion and experience</p>

<ul>
  <li>28 evaluation criteria for the clinical interpretation of variants. Criteria falls into 3 sets:
    <ul>
      <li>pathogenic/likely pathogenic (P/LP)</li>
      <li>benign/likely benign (B/LB)</li>
      <li>variant of unknown significance (VUS)</li>
    </ul>
  </li>
  <li><a href="http://wintervar.wglab.org"><strong>Intervar</strong></a>: software for automatical interpretation of the 28 criteria. Two major steps:</li>
  <li>automatical interpretation by 28 criteria</li>
  <li>manual adjustment to re-interpret the clinical significance</li>
</ul>

<h2 id="prioritization">Prioritization</h2>

<p>Phenotype-based prioritization tools are methods working by comparing the phenotypes of a patient with gene-phenotype known associations.</p>

<ul>
  <li><a href="http://phenolyzer.wglab.org/">Phenolyzer</a>: Phenotype Based Gene Analyzer, a tool to prioritize genes based on user-specific disease/phenotype terms</li>
</ul>

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-variant-prioritization"><i class="fa fa-pencil" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: Variant prioritization</h3>

  <p>Using knowledge gained on <a href="http://0.0.0.0:4000/clinical_genomics/lectures/04.db.html">Genomic databases and variant annotation</a> section, try to <strong><em>annotate</em></strong>, <strong><em>filter</em></strong> and <strong><em>prioritize</em></strong> an example exome variant data, using two disease terms</p>

  <ul>
    <li>
      <p>Download file Sample1.all_exons.hg19.vcf from the <em>dataset</em>, as learned in the <a href="http://0.0.0.0:4000/clinical_genomics/lectures/01.home.html">Home</a> section</p>
    </li>
    <li>
      <p>Go to <a href="http://wannovar.wglab.org/">wANNOVAR</a></p>
    </li>
    <li>
      <p>Use the vcf file as <strong>input file</strong> and <em>hearing loss</em> and <em>deafness autosomal recessive</em>, as disease terms to prioritize results</p>
    </li>
    <li>
      <p>Choose <em>rare recessive Mendelian disease</em> as Disease Model in the <strong><em>Parameter Settings</em></strong> section</p>
    </li>
    <li>
      <p>Provide an istitutional email address and submit the Job</p>
    </li>
    <li>
      <p>… <em>wait for results</em> …</p>

      <p>In the results page you can navigate and download results.
 Click <strong><em>Show</em></strong> in the <em>Network Visualization</em> section to see
 Phenolyzer prioritization results</p>
    </li>
  </ul>
</blockquote>

<h1 id="cnv-detection-from-targeted-sequencing-data">CNV detection from targeted sequencing data</h1>

<ul>
  <li><em>Copy Number Variants</em> (CNVs) are imbalances in the copy number of the genomic material that result in either <span class="notranslate">DNA</span> <strong>deletions</strong> (copy loss) or <strong>duplications</strong></li>
  <li><em>CNVs</em> can cause/predispose to human diseases by altering gene structure/dosage or by <strong>position effect</strong></li>
  <li><em>CNV</em> size ranges from 50 bp to megabases</li>
  <li>Classical methods to identify <em>CNVs</em> use array-based technologies (SNP/CGH)</li>
  <li>Computational approaches have been developed to identify <em>CNVs</em> in targeted sequencing data from <strong>hybrid capture</strong> experiments</li>
</ul>

<h2 id="computational-approaches">Computational approaches</h2>

<p>There are four main methods for <em>CNV</em> identification from short-read +NGS data (see figure below):</p>
<ul>
  <li><strong>Read Count</strong> (RC)</li>
  <li><strong>Read Pair</strong> (RP)</li>
  <li><strong>Split Read</strong> (SR)</li>
  <li>
    <p><strong>De Novo Assembly</strong> (AS)</p>
  </li>
  <li><em>RP</em> and <em>SR</em> require continuous coverage of the <em>CNV</em> region or <span class="notranslate">reads</span> encompassing <em>CNV</em> breakpoints, as in whole genome sequencing. The sparse nature and small size of exonic targets hamper the application of these methods to targeted sequencing.</li>
  <li><em>RC</em> is the best suited method for <em>CNV</em> detection from whole exomes or gene panels where:</li>
  <li>deletions appear as exonic targets devoid of <span class="notranslate">reads</span></li>
  <li>duplications appear as exonic targets characterized by excess of coverage</li>
</ul>

<hr />

<p><img src="/clinical_genomics/images/methods_identification_cnv.png" alt="CNV detection methods" /></p>

<p><strong>Figure 1</strong>. Methods for detection of CNVs in short read NGS data (adapted from <a href="https://doi.org/10.3389/fbioe.2015.00092">Tattini et al., 2015</a>)</p>

<hr />

<h2 id="rc-method-and-data-normalization">RC method and data normalization</h2>

<p>In targeted sequencing, a method to study <span class="notranslate">DNA</span> copy number variation by <em>RC</em> (as implemented in <em>EXCAVATOR</em> tool, <a href="http://genomebiology.com/2013/14/10/R120">Magi et al., 2013</a>)) is to consider the <strong>exon mean read count</strong> (EMRC):</p>

<p><em>EMRC</em> = <em>RC</em><sub>e</sub>/<em>L</em><sub>e</sub></p>

<p>where <em>RC</em><sub>e</sub> is the number of <span class="notranslate">reads</span> aligned to a target genomic region e and <em>L</em><sub>e</sub> is the size of that same genomic region in base pairs (<a href="http://genomebiology.com/2013/14/10/R120">Magi et al., 2013</a>)).
Three major bias sources are known to affect <em>EMRC</em> dramatically in targeted sequencing data:</p>
<ul>
  <li>local <strong>GC content</strong> percentage</li>
  <li>genomic <strong>mappability</strong></li>
  <li>target region <strong>size</strong></li>
</ul>

<p>These biases contribute to non uniform read depth across target regions and, together with the sparse target nature, challenge the applicability of <em>RC</em> methods to targeted data. As shown in Figure 2 (left panel), in single-sample data the <em>EMRC</em> distributions of genomic regions characterized by different copy numbers largely overlap, revealing poor <em>CNV</em> prediction capability.</p>

<p><em>EMRC ratio</em> between two samples can be used as a normalization procedure. The effect of <em>EMRC ratio</em>-based normalization is clear in Figure 2 (right panel) as a markedly improved correspondece between the predicted and the real copy number states.</p>

<hr />

<p><img src="/clinical_genomics/images/normalization_EMRC.png" alt="Data Normalization_1" /></p>

<p><strong>Figure 2</strong>. Effect of <em>EMRC ratio</em> on <span class="notranslate">DNA</span> copy number prediction (adapted from <a href="http://genomebiology.com/2013/14/10/R120">Magi et al., 2013</a>)</p>

<hr />

<p>Similarly FPKM, a normalized measure of read depth implemented in ExomeDepth tool (<a href="https://doi.org/10.1093/bioinformatics/bts526">Plagnol et al., 2012</a>), is affected by extensive exon–exon variability but comparison between pairs of exome datasets demonstrates high correlation level of the normalized read count data across samples making it possibile to use one or more combined exomes as reference set to base the CNV inference on (<a href="https://doi.org/10.1093/bioinformatics/bts526">Plagnol et al., 2012</a>).</p>

<hr />

<p><img src="/clinical_genomics/images/normalization_FPKM.png" alt="Data Normalization_2" /></p>

<p><strong>Figure 3</strong>. Correlation of the normalized read count data between samples (from <a href="https://doi.org/10.1093/bioinformatics/bts526">Plagnol et al., 2012</a>)</p>

<hr />

<h2 id="cnv-detection-accuracy"><em>CNV</em> detection accuracy</h2>

<p>Strong correlation is observed between Affymetrix array-SNP and exome-derived data for <em>CNVs</em> &gt;1 Mb (Figure 4, right panel), while including CNVs of any size dramatically decreases the correlation level (Figure 4, left panel). This can be explained by the different distribution of exons and SNP probes throughout the genome. Candidate <em>CNV</em> regions as identified by <em>EXCAVATOR</em> contain a comparable number of exons and SNP probes when they are &gt; 1 Mb (<em>R</em>=0.8), while regions &lt;100 Kb do not (<em>R</em>=-0.02). Accordingly, <a href="https://genome.cshlp.org/content/22/8/1525.full">Krumm et al., 2012</a> report 94% precision in detecting <em>CNVs</em> across three or more exons.</p>

<hr />

<p><img src="/clinical_genomics/images/corr_exome_affymetrix.png" alt="Correlation_Exome_Affymetrix" /></p>

<p><strong>Figure 4</strong>. Correlation between array-SNP and exome-derived <em>CNVs</em> including all (left panel) or &gt; 1 Mb <em>CNVs</em> (adapted from <a href="http://genomebiology.com/2013/14/10/R120">Magi et al., 2013</a>)</p>

<hr />

<p>To increase chances to detect <em>CNVs</em> encompassing few exons or in non-coding regions from exome data, <a href="https://academic.oup.com/nar/article/44/20/e154/2607979">D’Aurizio et al., 2016</a> have proposed an extension to <em>EXCAVATOR</em> to exploit off-target read count (<em>EXCAVATOR2</em>). Similar approaches taking advantage of off-target <span class="notranslate">reads</span> have been described by <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4147927/">Bellos et al., 2014</a> or <a href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1004873">Talevich et al., 2016</a>.</p>

<h2 id="tools-for-cnv-detection-from-gene-panels-or-exome-data">Tools for <em>CNV</em> detection from gene panels or exome data</h2>

<p>A number of tools or pipelines implementing modified versions of previously published tools have been reported to detect single-exon <em>CNVs</em> in clinical gene panels:</p>
<ul>
  <li><a href="https://onlinelibrary.wiley.com/doi/full/10.1002/humu.22969">CoNVaDING</a></li>
  <li><a href="https://wellcomeopenresearch.org/articles/1-20/v1">DeCON</a></li>
  <li><a href="https://www.nature.com/articles/ejhg201742">ExomeDepth v1.1.6</a></li>
  <li><a href="https://www.nature.com/articles/s41436-019-0475-4">Atlas-CNV</a></li>
  <li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6192323/">DeviCNV</a></li>
</ul>

<p>In addition to the above-mentioned methods, many tools have been developed that detect <em>CNVs</em> from exomes. Evaluation of these tools is not straightforward as there is lack of a gold standard for comparison. As a consequence, there is no consensus level on pipelines as high as for single nucleotide variants. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5452530/pdf/12859_2017_Article_1705.pdf">Zare et al., 2017</a> have reviewed this topic with focus on cancer, reporting poor overlap of different tools and added challenges for somatic variant calling.</p>

<hr />

<blockquote class="notranslate hands_on">
  <h3 id="hands_on-hands-on-cnv-calling-with-exomedepth"><i class="fa fa-pencil" aria-hidden="true"></i><span class="visually-hidden">hands_on</span> Hands-on: CNV calling with ExomeDepth</h3>
  <p>ExomeDepth uses pairs of case and control exomes to identify copy number imbalances in case(s) compared to control(s).
   Here we provide a small data set including a pair of case/control BAM files and an exome target <span class="notranslate">BED</span> file restricted to a specific polymorphic region on chromosome 2q.</p>

  <ul>
    <li>CNV_case.bam.</li>
    <li>CNV_control.bam.</li>
    <li>
      <p>CNV_TruSeq_Chr2.bam</p>

      <p>Your aim is to identify a large polymorphic deletion in case.</p>
    </li>
  </ul>
</blockquote>

<h1 id="regions-of-homozygosity">Regions of Homozygosity</h1>

<ul>
  <li><em>Runs of Homozygosity</em> (ROHs) are sizeable stretches of consecutive homozygous markers encompassing genomic regions where the two haplotypes are identical</li>
  <li>Haplotypes in <em>ROHs</em> can underlie identity either by <strong>state</strong> (IBS) or by <strong>descent</strong> (IBD). IBD occurs when two haplotypes originate from a common ancestor (Figure 1), a condition whcih we refer to as <strong>autozygosity</strong></li>
  <li><em>Autozygosity</em> in an individual is the hallmark of high levels of genomic inbreeding (g<em>F</em>), often occurring in the offspring from consanguineous unions where parents are related as second-degree cousins or closer</li>
  <li>The most well-known medical impact of parental consanguinity is the increased risk of rare autosomal recessive diseases in the progeny, with excess risk inversely proportional to the disease-allele frequency (<a href="https://onlinelibrary.wiley.com/doi/full/10.1034/j.1399-0004.2001.600201.x?sid=nlm%3Apubmed">Bittles, 2001</a>)</li>
</ul>

<hr />

<p><img src="/clinical_genomics/images/homozygosity_mapping.png" alt="homozygosity_mapping" />
<strong>Figure 1</strong>. Schematic of haplotype flow along a consanguineous pedigrees to form autozygous <em>ROHs</em> in the progeny (from <a href="https://www.sciencedirect.com/science/article/pii/S000292970800445X?via%3Dihub">McQuillan et al., 2008</a>)</p>

<hr />

<h2 id="homozygosity-mapping">Homozygosity <span class="notranslate">mapping</span></h2>

<ul>
  <li>We refer to <em>homozygosity <span class="notranslate">mapping</span></em> (<a href="https://science.sciencemag.org/content/236/4808/1567.long">Lander and Botstein, 1987</a>) as an approach that infers <em>autozygosity</em> from the detection of long ROHs to map genes associated with recessive diseases</li>
  <li>A classical strategy to identify <em>ROHs</em> is based on SNP-array data and analysis with <a href="http://zzz.bwh.harvard.edu/plink/">PLINK</a></li>
  <li>The combination of <em>homozygosity <span class="notranslate">mapping</span></em> with exome sequencing has boosted genomic research and diagnosis of recessive diseases in recent years (<a href="https://www.sciencedirect.com/science/article/pii/S2211124714010444?via%3Dihub">Alazami et al., 2015</a>; <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5502059/">Monies et al., 2017</a>)</li>
  <li><em>ROHs</em> may be of clinical interest also since they can unmask <strong>uniparental isodisomy</strong></li>
  <li>Computational approaches have been developed to identify <em>ROHs</em> directly in exome data, allowing <strong>simultaneous detection of variants and surrounding ROHs</strong> from the same datasets.</li>
</ul>

<h2 id="computational-approaches-1">Computational approaches</h2>

<p>As for CNVs, the sparse nature and small size of exonic targets are a challenge for the identification of continuous strethces of homozygous markers throughout the genome. This may affect the performance of tools originally tailored to SNPs when applied to exome data.</p>

<p>In Figure 2 a synthetic overview is given of algorithms, input data and output file types in bioinformatic tools for exome-based <em>ROH</em> detection. <em>ROHs</em> are divided in three size classes reflecting different mechanisms that have shaped them (according to <a href="https://www.sciencedirect.com/science/article/pii/S0002929712003230?via%3Dihub">Pemberton et al., 2012</a>).</p>

<p>Usually, long ROH (approximately &gt;1.5 Mb) arise as a result of close parental consanguinity, but also short-medium <em>ROHs</em> can be of medical interest in populations as involved in disease susceptibility, natural selection and founder effects (<a href="https://www.nature.com/articles/nrg.2017.109">Ceballos et al., 2018</a>).</p>

<hr />

<p><img src="/clinical_genomics/images/roh_exome_methods.png" alt="roh_exome_methods" />
<strong>Figure 2</strong>. Summary of the tools for <em>ROH</em> detection from exome data (from <a href="https://www.karger.com/Article/Pdf/362412">Pippucci et al., 2014</a>)</p>

<hr />

<h3 id="h3m2">H<sup>3</sup>M<sup>2</sup></h3>

<p><em>H<sup>3</sup>M<sup>2</sup></em> (<a href="https://academic.oup.com/bioinformatics/article/30/20/2852/2422169">Magi et al., 2014</a>) is based on an heterogeneous <a href="https://en.wikipedia.org/wiki/Hidden_Markov_model"><em>Hidden Markov Model</em></a> (HMM) that incorporates inter-marker distances to detect <em>ROHs</em> from exome data.</p>

<p><em>H<sup>3</sup>M<sup>2</sup></em> calculates B-allele frequencies of a set of polymorphic sites throughout the exome as the ratio between allele <em>B</em> counts and the total read count at site <em>i</em>:</p>

<p><em>BAF</em><sub>i</sub> = <em>N<sub>b</sub>/N</em></p>

<p><em>H<sup>3</sup>M<sup>2</sup></em> retrieves <em>BAF</em><sub>i</sub> <strong>directly from BAM files</strong> to predict the heterozygous/homozygous genotype state at each polymorphic position <em>i</em>:</p>

<ul>
  <li>when <em>BAF</em><sub>i</sub> ~ 0 the predicted genotype is <strong>homozygous reference</strong></li>
  <li>when <em>BAF</em><sub>i</sub> ~ 0.5 the predicted genotype is <strong>heterozygous</strong></li>
  <li>when <em>BAF</em><sub>i</sub> ~ 1 the predicted genotype is <strong>homozygous alte<span class="notranslate">rna</span>tive</strong></li>
</ul>

<p><em>H<sup>3</sup>M<sup>2</sup></em> models <em>BAF</em> data by means of the <em>HMM</em> algorithm to discriminate between regions of homozygosity and non-homozygosity according to the <em>BAF</em> distribution along the genome (Figure 3).</p>

<hr />

<p><img src="/clinical_genomics/images/h3m2_baf.png" alt="h3m2_baf" />
<strong>Figure 3</strong>. <strong><em>BAF</em> data distribution</strong> Panels a, b and c show the distributions of BAF values against the genotype calls generated by the HapMap consortium on SNP-array data ( a ), the genotype calls made by SAMtools ( b ) and the genotype calls made by GATK ( c ). For each genotype caller, the distribution of BAF values is reported for homozygous reference calls (HMr), heterozygous calls (HT) and homozygous alte<span class="notranslate">rna</span>tive calls (HMa). R is the Pearson correlation coefficient. Panels d–g show the distribution of BAF values in all the regions of the genome ( d ), in heterozygous regions ( e ), in homozygous regions ( f ) and in the X chromosome of male individuals ( g ). For each panel, the main plot reports the zoomed histogram, the left subplot shows the BAF values against genomic positions, whereas the right subplot shows the entire histogram of BAF values. (from <a href="https://academic.oup.com/bioinformatics/article/30/20/2852/2422169">Magi et al., 2014</a>)</p>

<h1 class="no_toc" id="contributors">Contributors</h1>

<ul>
  <li><a href="https://www.aosp.bo.it/content/curriculum?E=154659">Tommaso Pippucci</a> - Sant’Orsola-Malpighi University Hospital, Bologna, Italy</li>
  <li><a href="https://www">Alessandro Bruselles</a> - Istituto Superiore di Sanità, Rome, Italy</li>
  <li><a href="http://www.ospedalebambinogesu.it">Andrea Ciolfi</a> - Ospedale Pediatrico Bambino Gesù, IRCCS, Rome, Italy</li>
  <li><a href="https://gmauro.github.io">Gianmauro Cuccuru</a> - Albert Ludwigs University, Freiburg, Germany</li>
  <li><a href="http://www">Giuseppe Marangi</a> - Institute of Genomic Medicine, Fondazione Policlinico Universitario A. Gemelli IRCCS, Università Cattolica del Sacro Cuore, Roma, Italy</li>
  <li><a href="http://www.crs4.it/peopledetails/183/paolo-uva">Paolo Uva</a> - Centro di Ricerca, Sviluppo e Studi Superiori in Sardegna (CRS4), Pula, Cagliari, Italy</li>
</ul>



                    
                    <blockquote class="key_points">
                        <h3><i class="fa fa-key" aria-hidden="true"></i><span class="visually-hidden">keypoints</span> Key points</h3>
                        <ul>
                            
                            <li><p>Focus on clinical interpretation of variants.</p>
</li>
                            
                            <li><p>Provides real uses cases.</p>
</li>
                            
                            <li><p>Use public tools and free annotation servers.</p>
</li>
                            
                        </ul>
                    </blockquote>
                    

                    

                    

                    <h1>Citing this Tutorial</h1>
                    <p>
                        <ol>
                            <li id="citation-text">Alessandro Bruselles, Andrea Ciolfi, Gianmauro Cuccuru, Giuseppe Marangi, Paolo Uva, Tommaso Pippucci, 2020 <b>Data analysis and interpretation for clinical genomics (Galaxy Training Materials)</b>. <a href="/clinical_genomics/">/clinical_genomics/</a> Online; accessed TODAY
                            </li>
                            <li>
                            Batut et al., 2018 <b>Community-Driven Data Analysis Training for Biology</b> Cell Systems <a href="https://doi.org/10.1016%2Fj.cels.2018.05.012">10.1016/j.cels.2018.05.012</a>
                            </li>
                        </ol>
                    </p>


                    <blockquote class="details">
                      <h3><i class="fa fa-info-circle" aria-hidden="true"></i><span class="visually-hidden">details</span> BibTeX</h3>
                      <p style="display: none;">

                    <div class="highlighter-rouge"><div class="highlight"><pre class="highlight">
<code id="citation-code">@misc{-,
    author = "Alessandro Bruselles and Andrea Ciolfi and Gianmauro Cuccuru and Giuseppe Marangi and Paolo Uva and Tommaso Pippucci",
    title = "Data analysis and interpretation for clinical genomics (Galaxy Training Materials)",
    year = "2020",
    month = "01",
    day = "24"
    url = "\url{/clinical_genomics/}",
    note = "[Online; accessed TODAY]"
}
@article{Batut_2018,
        doi = {10.1016/j.cels.2018.05.012},
        url = {https://doi.org/10.1016%2Fj.cels.2018.05.012},
        year = 2018,
        month = {jun},
        publisher = {Elsevier {BV}},
        volume = {6},
        number = {6},
        pages = {752--758.e1},
        author = {B{\'{e}}r{\'{e}}nice Batut and Saskia Hiltemann and Andrea Bagnacani and Dannon Baker and Vivek Bhardwaj and Clemens Blank and Anthony Bretaudeau and Loraine Brillet-Gu{\'{e}}guen and Martin {\v{C}}ech and John Chilton and Dave Clements and Olivia Doppelt-Azeroual and Anika Erxleben and Mallory Ann Freeberg and Simon Gladman and Youri Hoogstrate and Hans-Rudolf Hotz and Torsten Houwaart and Pratik Jagtap and Delphine Larivi{\`{e}}re and Gildas Le Corguill{\'{e}} and Thomas Manke and Fabien Mareuil and Fidel Ram{\'{\i}}rez and Devon Ryan and Florian Christoph Sigloch and Nicola Soranzo and Joachim Wolff and Pavankumar Videm and Markus Wolfien and Aisanjiang Wubuli and Dilmurat Yusuf and James Taylor and Rolf Backofen and Anton Nekrutenko and Björn Grüning},
        title = {Community-Driven Data Analysis Training for Biology},
        journal = {Cell Systems}
}</code>
                    </pre></div></div>
                    </p>
                    </blockquote>


<script type="text/javascript">
// update the date on load, or leave fallback of 'today'
d = new Date();
document.getElementById("citation-code").innerHTML = document.getElementById("citation-code").innerHTML.replace("TODAY", d.toDateString());
document.getElementById("citation-text").innerHTML = document.getElementById("citation-text").innerHTML.replace("TODAY", d.toDateString());
</script>

                </div>
            </div>
        </div>

        <h3><i class="fa fa-thumbs-up" aria-hidden="true"></i><span class="visually-hidden">congratulations</span> Congratulations on successfully completing this tutorial!</h3>

        

        

        <hr>
        <br>

        <blockquote class="feedback">
            <h3><i class="fa fa-comments-o" aria-hidden="true"></i><span class="visually-hidden">feedback</span> Give us feedback on this content!</h3>
            <p>To give us feedback about these materials, or to get in touch with us, post a message in
               the forum <a href="https://groups.google.com/d/forum/sigu-training">https://groups.google.com/d/forum/sigu-training</a>.</p>
        </blockquote>
    </section>
</div>


<footer>
    <div class="container">
        <p>
            The layout of this page is based on the <a href="https://training.galaxyproject.org/">Galaxy Training Resources</a> collection.
        </p>
        <p>
            Found a typo? Something is wrong in this tutorial? Edit it on
            <a href="https://github.com/sigu-training/clinical_genomics/blob/master/index.md">GitHub</a>.
        </p>
    </div>
</footer>

    </body>
    <script type="text/javascript" src="/clinical_genomics/assets/js/jquery.slim.min.js"></script>
    <script type="text/javascript" src="/clinical_genomics/assets/js/popper.min.js"></script>
    <script type="text/javascript" src="/clinical_genomics/assets/js/bootstrap.min.js?v=3"></script>
    <script type="text/javascript" src="/clinical_genomics/assets/js/details-element-polyfill.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="/clinical_genomics/assets/js/bootstrap-toc.min.js"></script>
    <script type="text/javascript" src="/clinical_genomics/assets/js/main.js"></script>

    <script type="text/javascript" src="/clinical_genomics/assets/js/clipboard.min.js"></script>
    <script type="text/javascript">
    var snippets=document.querySelectorAll('div.highlight');
    [].forEach.call(snippets,function(snippet){
        snippet.firstChild.insertAdjacentHTML('beforebegin','<button class="btn btn-light" data-clipboard-snippet><i class="fa fa-copy"></i>&nbsp;Copy</button>');
    });

    var clipboardSnippets=new ClipboardJS('[data-clipboard-snippet]',{
        target:function(trigger){return trigger.nextElementSibling;
    }});
    </script>
    
</html>
